---
title: Hospital Stay Models
author: 
  - name: Adam Gilbert
    email: a.gilbert1@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
format: html
date: 2/24/2025
date-modified: today
date-format: long
theme: flatly
toc: true
code-fold: true
message: false
warning: false
---

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(kableExtra)

# styling
options(kable_styling_bootstrap_options = c("hover", "striped"))
theme_set(theme_bw(base_size = 14))

unregister <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

data <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/master/data/classification/hospital_stays_small.csv")

names(data) <- janitor::make_clean_names(names(data))

set.seed(123)
data_splits <- initial_split(data, strata = stay)
train <- training(data_splits)
test <- testing(data_splits)

train_folds <- vfold_cv(train, v = 10, strata = stay)

```

## Initializing KNN Model

```{r}

knn_spec <- nearest_neighbor(mode = "classification")

knn_rec <- recipe(stay ~., data = train) |>
  step_normalize(all_numeric_predictors()) |>
  step_rm(all_nominal_predictors()) |>
  step_rm(case_id) |>
  step_impute_median(all_numeric_predictors())

knn_wf <- workflow() |>
  add_model(knn_spec) |>
  add_recipe(knn_rec)

```

## Using Cross Validation

```{r cv}
#| eval: false

n_cores <- parallel::detectCores()
cluster <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cluster)

tictoc::tic()

knn_cv_results <- knn_wf |>
  fit_resamples(
    resamples = train_folds,
    metrics = metric_set(accuracy, mn_log_loss)
  )
  
tictoc::toc()

doParallel::stopImplicitCluster()
unregister()

```

```{r}
#save(knn_cv_results, knn_wf, file = "knn_cv_results.RData")
load("knn_cv_results.RData")

knn_cv_results |>
  collect_metrics() |>
  kable() |>
  kable_styling()

```

### Hyperparamater Tuning with Parallel Processing

```{r}
#| label: about-7-min
#| eval: false

n_cores <- parallel::detectCores()
cl <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cl)

tictoc::tic()

knn_tune_results <- knn_tune_wf %>%
  tune_bayes(
    resamples = train_folds,
    metrics = metric_set(mn_log_loss),
    control = control_bayes(parallel_over = "everything")
  )

tictoc::toc()

doParallel::stopImplicitCluster()
unregister()

knn_cv_results %>%
  collect_metrics()

```

## Fit KNN with Optimal Neighbors (Best Hyperparameters)

```{r}
#| eval: false

knn_best_params <- knn_tune_results %>%
  select_best(metric = "mn_log_loss")

knn_best_wf <- knn_tune_wf %>%
  finalize_workflow(knn_best_params)

knn_best_fit <- knn_best_wf %>%
  fit(train)

```

## Plotting Decision Boundary

```{r}
#| eval: false

new_data <- crossing(
  case_id = NA,
  hospital_code = median(train$hospital_code, na.rm = TRUE),
  hospital_type_code = mode(train$hospital_type_code),
  city_code_hospital = median(train$city_code_hospital),
  hospital_region_code = mode(train$hospital_code),
  available_extra_rooms_in_hospital = seq(min(train$available_extra_rooms_in_hospital, na.rm = TRUE),
            max(train$available_extra_rooms_in_hospital, na.rm = TRUE), 
            length.out = 100),
  department = mode(train$department),
  ward_type = mode(train$ward_type),
  ward_facility_code = mode(train$ward_facility_code),
  bed_grade = median(train$bed_grade, na.rm = TRUE),
  patientid = median(train$patientid, na.rm = TRUE),
  city_code_patient = median(train$city_code_patient, na.rm = TRUE),
  type_of_admission = mode(train$type_of_admission),
  severity_of_illness = mode(train$severity_of_illness),
  visitors_with_patient = median(train$visitors_with_patient, na.rm = TRUE),
  age = mode(train$age),
  admission_deposit = seq(min(train$admission_deposit, na.rm = TRUE),
            max(train$admission_deposit, na.rm = TRUE), 
            length.out = 100),
)

knn_best_fit %>%
  augment(new_data) %>%
  ggplot() + 
  geom_point(aes(x = admission_deposit, y = available_extra_rooms_in_hospital, color = .pred_class), alpha = 0.2) + 
  guides(color = guide_legend(override.aes = list(alpha = 1)))

```

## Decision Tree

```{r}

dt_spec <- decision_tree(tree_depth = tune(), min_n = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

dt_rec <- recipe(stay ~ ., data = train) |>
  step_impute_median(all_numeric_predictors()) |>
  step_impute_mode(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors())

dt_tune_wf <- workflow() |>
  add_model(dt_spec) |>
  add_recipe(dt_rec)

```

```{r}
#| eval: false

n_cores <- parallel::detectCores()
cl <- parallel::makeCluster(n_cores - 1, type = "PSOCK")
doParallel::registerDoParallel(cl)

tictoc::tic()

dt_tune_results <- dt_tune_wf %>%
  tune_bayes(
    resamples = train_folds,
    metrics = metric_set(mn_log_loss),
    initial = 5,
    control = control_bayes(parallel_over = "everything")
  )

tictoc::toc()

doParallel::stopImplicitCluster()
unregister()

```

```{r}

#save(dt_tune_results, dt_tune_wf, file = "dt_tune_results.RData")
load("dt_tune_results.RData")

dt_tune_results %>%
  collect_metrics() |>
  kable() |>
  kable_styling()

```

```{r}

dt_tune_results |>
  show_best(n = 10) |>
  kable() |>
  kable_styling()

```

```{r}

dt_best_params <- dt_tune_results %>%
  select_best(metric = "mn_log_loss")

dt_best_wf <- dt_tune_wf %>%
  finalize_workflow(dt_best_params)

dt_best_fit <- dt_best_wf %>%
  fit(train)

```

```{r}

dt_best_fit |>
  augment(train) |>
  mutate(stay = as.factor(stay)) |>
  accuracy(stay, .pred_class) |>
  kable() |>
  kable_styling()

```

